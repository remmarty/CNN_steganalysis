{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "from torchmetrics import *\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.checkpoint as cp\n",
    "import torch.utils.data as ud\n",
    "from torch.nn.utils import clip_grad as cg\n",
    "from torch.optim.lr_scheduler import StepLR, LambdaLR\n",
    "from torch.utils.data import DataLoader, Dataset, Sampler, RandomSampler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms\n",
    "import separableconv.nn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import NeptuneLogger\n",
    "from neptune.new.types import File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if its possible to use GPU/CUDA\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"garbage_collection_threshold:0.9,max_split_size_mb:128\"\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "print(torch.version.cuda)\n",
    "print(torch.version)\n",
    "print(torchvision.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"train_batch_size\": 16,\n",
    "    \"val_batch_size\": 16,\n",
    "    \"test_batch_size\": 16,\n",
    "    \"lr\": 0.005,\n",
    "    \"momentum\": 0.9,\n",
    "    \"weight_decay\": 5e-4,\n",
    "    \"max_epochs\": 200,\n",
    "    \"schedule\": [50, 100, 150],\n",
    "    \"gamma\": 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'E:/WOW_04BPP/train'\n",
    "val_dir = 'E:/WOW_04BPP/val'\n",
    "test_dir = 'E:/WOW_04BPP/test'\n",
    "\n",
    "class Data(pl.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        self.num_workers = 0\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.train = ImageFolder(root=train_dir, transform=self.transform)\n",
    "        self.val = ImageFolder(root=val_dir, transform=self.transform)\n",
    "        self.test = ImageFolder(root=test_dir, transform=self.transform)\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        if stage == \"fit\":\n",
    "            train_indices = list(range(len(self.train)))\n",
    "            train_sampler = RandomSampler(train_indices, replacement=False, num_samples=None, generator=torch.Generator().manual_seed(42))\n",
    "            self.train_set = DataLoader(self.train, batch_size=params[\"train_batch_size\"], sampler=train_sampler,\n",
    "                                         num_workers=self.num_workers, pin_memory=True, drop_last=True) \n",
    "            val_indices = list(range(len(self.val)))\n",
    "            val_sampler = RandomSampler(val_indices, replacement=False, num_samples=None, generator=torch.Generator().manual_seed(42))\n",
    "            self.val_set = DataLoader(self.val, batch_size=params[\"val_batch_size\"], sampler=val_sampler,\n",
    "                                    num_workers=self.num_workers, pin_memory=True, drop_last=True)\n",
    "            \n",
    "        if stage == \"test\": \n",
    "            test_indices = list(range(len(self.test)))\n",
    "            test_sampler = RandomSampler(test_indices, replacement=False, num_samples=None, generator=torch.Generator().manual_seed(42))\n",
    "            self.test_set = DataLoader(self.test, batch_size=params[\"test_batch_size\"], sampler=test_sampler, \n",
    "                                    num_workers=self.num_workers, pin_memory=True, drop_last=True)\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        return self.train_set\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.val_set\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.test_set\n",
    "    \n",
    "data_module = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABS(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ABS, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = torch.abs(x)\n",
    "        return output\n",
    "    \n",
    "class TLU(nn.Module):\n",
    "    def __init__(self, threshold):\n",
    "        super(TLU, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = torch.clamp(input, min=-self.threshold, max=self.threshold)\n",
    "\n",
    "        return output\n",
    "    \n",
    "class ScaleLayer(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(ScaleLayer, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(num_features))\n",
    "        self.beta = nn.Parameter(torch.zeros(num_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.gamma.view(1, -1, 1, 1) + self.beta.view(1, -1, 1, 1)\n",
    "\n",
    "def plot_roc(y, preds, pred_scores, is_test):\n",
    "    fpr_0, tpr_0, _ = roc_curve(1 - y, 1 - pred_scores)\n",
    "    roc_auc_0 = auc(fpr_0, tpr_0)\n",
    "\n",
    "    fpr_1, tpr_1, _ = roc_curve(y, preds[:, 1])\n",
    "    roc_auc_1 = auc(fpr_1, tpr_1)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.plot(fpr_0, tpr_0, label='Class 0: Cover (AUC = {:.2f})'.format(roc_auc_0))\n",
    "    plt.plot(fpr_1, tpr_1, label='Class 1: Stego (AUC = {:.2f})'.format(roc_auc_1))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', label='Random (AUC = 0.5)')\n",
    "    plt.title(\"Receiver Operating Characteristics\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    if is_test:\n",
    "        neptune_logger.experiment[\"test_ROC\"].append(File.as_image(fig))\n",
    "\n",
    "def plot_confusion_matrix(confusion_mat, is_test):\n",
    "    classes = ['Cover', 'Stego']\n",
    "\n",
    "    confusion_mat = confusion_mat.astype('float') / confusion_mat.sum(axis=1)[:, np.newaxis]\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(confusion_mat, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Normalized Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    for i in range(confusion_mat.shape[0]):\n",
    "        for j in range(confusion_mat.shape[1]):\n",
    "            plt.text(j, i, format(confusion_mat[i, j], '.2f'),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if confusion_mat[i, j] > 0.5 else \"black\")\n",
    "\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "    if is_test:\n",
    "        neptune_logger.experiment[\"test_CM\"].append(File.as_image(fig))\n",
    "\n",
    "def Tanh3(x):\n",
    "    tanh3 = 3 * torch.tanh(x)\n",
    "    return tanh3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srm_weights = np.load('SRM_filters.npy')*(1/12)\n",
    "biasSRM = np.ones(30)\n",
    "\n",
    "srm_weights_tensor = torch.from_numpy(srm_weights).permute(3,2,0,1).cuda()\n",
    "biasSRM_tensor = torch.from_numpy(biasSRM).cuda().float()\n",
    "\n",
    "### Define CNN architecture ###\n",
    "class Yedroudj(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.val_ytrue = []\n",
    "        self.val_ypred = []\n",
    "        self.test_ytrue = []\n",
    "        self.test_ypred = []\n",
    "        self.tlu_3 = TLU(3.0)\n",
    "        self.tlu_1 = TLU(1.0)\n",
    "        self.abs = ABS()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.srm_weights = torch.nn.Parameter(srm_weights_tensor, requires_grad=False)\n",
    "        self.biasSRM = torch.nn.Parameter(biasSRM_tensor, requires_grad=True)\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(num_features=30)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=30, out_channels=30, kernel_size=5, stride=1, padding=\"same\")\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=30)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=30, out_channels=30, kernel_size=5, stride=1, padding=\"same\")\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=30)\n",
    "       \n",
    "        self.conv3 = nn.Conv2d(in_channels=30, out_channels=32, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=32)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=64)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.bn5 = nn.BatchNorm2d(num_features=128)\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(128, 256)\n",
    "        self.fc2 = torch.nn.Linear(256, 2)\n",
    "\n",
    "    def init_weights(self, module):\n",
    "        if type(module) == nn.Conv2d:\n",
    "            if module.weight.requires_grad:\n",
    "                nn.init.kaiming_normal_(module.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "        if type(module) == nn.Linear:\n",
    "            nn.init.normal_(module.weight.data, mean=0, std=0.01)\n",
    "            nn.init.constant_(module.bias.data, val=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.conv2d(x, self.srm_weights, self.biasSRM, stride=1, padding=\"same\")\n",
    "        x = self.relu(x)  \n",
    "        x = self.bn(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.abs(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.tlu_3(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.tlu_1(x)\n",
    "        x = nn.AvgPool2d(kernel_size=5, stride=2, padding=2)(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = nn.AvgPool2d(kernel_size=5, stride=2, padding=2)(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "        x = nn.AvgPool2d(kernel_size=5, stride=2, padding=2)(x)\n",
    "      \n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = x.view(-1, 128)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(\n",
    "            self.parameters(), lr=params[\"lr\"], momentum=params[\"momentum\"], weight_decay=params[\"weight_decay\"]\n",
    "        )\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=params[\"schedule\"], gamma=params[\"gamma\"])\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        pred = self(x)\n",
    "       \n",
    "        target = F.one_hot(y, num_classes=2).float()\n",
    "        preds = pred.float()\n",
    "\n",
    "        loss = F.binary_cross_entropy(preds, target)\n",
    "        self.log(\"train/loss\", loss, on_step=False, on_epoch=True)\n",
    "        \n",
    "        y_true = y\n",
    "        y_pred = pred.argmax(dim=1)\n",
    "\n",
    "        acc = accuracy_score(y_true.cpu().numpy(), y_pred.cpu().numpy())\n",
    "        self.log(\"train/acc\", acc, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        pred = self(x)\n",
    "\n",
    "        target = F.one_hot(y, num_classes=2).float()\n",
    "        preds = pred.float()\n",
    "        \n",
    "        loss = F.binary_cross_entropy(preds, target)\n",
    "        self.log(\"val/loss\", loss, on_step=False, on_epoch=True)\n",
    "\n",
    "        y_true = y\n",
    "        y_pred = pred.argmax(dim=1)\n",
    "\n",
    "        acc = accuracy_score(y_true.cpu().numpy(), y_pred.cpu().numpy())\n",
    "        self.log(\"val/acc\", acc, on_step=False, on_epoch=True)\n",
    "\n",
    "        self.val_ytrue.append(y.detach())\n",
    "        self.val_ypred.append(pred.detach())\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        y = torch.stack(self.val_ytrue).cpu().numpy()\n",
    "        preds = torch.stack(self.val_ypred).cpu().numpy()\n",
    "        \n",
    "        y = torch.tensor(y).reshape(-1)\n",
    "        preds = torch.tensor(preds).reshape(-1, 2)\n",
    "\n",
    "        pred_scores = preds[:, 1]\n",
    "\n",
    "        plot_roc(y, preds, pred_scores, False)\n",
    "            \n",
    "        cm_pred = (pred_scores.numpy() >= 0.5).astype(int)\n",
    "        cm = confusion_matrix(y, cm_pred)\n",
    "        plot_confusion_matrix(cm, False)\n",
    "            \n",
    "        self.val_ytrue.clear()\n",
    "        self.val_ypred.clear()\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        pred = self(x)\n",
    "\n",
    "        target = F.one_hot(y, num_classes=2).float()\n",
    "        preds = pred.float()\n",
    "        \n",
    "        loss = F.binary_cross_entropy(preds, target)\n",
    "        self.log(\"test/loss\", loss, on_step=False, on_epoch=True)\n",
    "\n",
    "        self.test_ytrue.append(y.detach())\n",
    "        self.test_ypred.append(pred.detach())\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        y = torch.stack(self.test_ytrue).cpu().numpy()\n",
    "        preds = torch.stack(self.test_ypred).cpu().numpy()\n",
    "        \n",
    "        y = torch.tensor(y).reshape(-1)\n",
    "        preds = torch.tensor(preds).reshape(-1, 2)\n",
    "\n",
    "        acc_metric = torchmetrics.Accuracy(task='multiclass', num_classes=2)\n",
    "        acc = acc_metric(preds, y)\n",
    "        self.log(\"test/acc\", acc)\n",
    "\n",
    "        prec_metric = torchmetrics.Precision(task='multiclass', num_classes=2)\n",
    "        prec = prec_metric(preds, y)\n",
    "        self.log(\"test/prec\", prec)\n",
    "\n",
    "        recall_metric = torchmetrics.Recall(task='multiclass', num_classes=2)\n",
    "        recall = recall_metric(preds, y)\n",
    "        self.log(\"test/recall\", recall)\n",
    "        \n",
    "        f1_metric = torchmetrics.F1Score(task='multiclass', num_classes=2)\n",
    "        f1 = f1_metric(preds, y)\n",
    "        self.log(\"test/f1\", f1)\n",
    "\n",
    "        pred_scores = preds[:, 1]\n",
    "    \n",
    "        plot_roc(y, preds, pred_scores, True)\n",
    "            \n",
    "        cm_pred = (pred_scores.numpy() >= 0.5).astype(int)\n",
    "        cm = confusion_matrix(y, cm_pred)\n",
    "        plot_confusion_matrix(cm, True)\n",
    "            \n",
    "        self.test_ytrue.clear()\n",
    "        self.test_ypred.clear()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NeptunLogger\n",
    "neptune_logger = NeptuneLogger(\n",
    "    api_key=\"\", # you must enter your own account api key generated by Neptune.ai\n",
    "    project=\"\", # same with the project name etc.\n",
    "    project=\"remmarty/Yedroudj-WOW\",\n",
    "    prefix=\"experiment\",\n",
    "    tags=[\"BossBase_8/1/1, srm filters\"],\n",
    "    log_model_checkpoints=True, \n",
    "    capture_hardware_metrics=False,\n",
    "    capture_stdout=False,\n",
    "    source_files=\"yedroudj_2.ipynb\"\n",
    ")\n",
    "\n",
    "run_id = neptune_logger.run[\"sys/id\"].fetch()\n",
    "folder_name = run_id\n",
    "log_path = \"E:/YEDROUDJ_WOW_CHECKPOINTS\"\n",
    "\n",
    "path = os.path.join(log_path, folder_name)\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Create learning rate logger\n",
    "lr_logger = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "\n",
    "# Create model checkpointing object\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    dirpath=path,\n",
    "    mode=\"max\",\n",
    "    monitor=\"val/acc\",\n",
    "    save_weights_only=False,\n",
    "    save_top_k=100,\n",
    "    save_last=True,\n",
    "    every_n_epochs=1,\n",
    ")\n",
    "\n",
    "# Initialize a trainer and pass neptune_logger\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=path,\n",
    "    logger=neptune_logger,\n",
    "    callbacks=[lr_logger, model_checkpoint],\n",
    "    log_every_n_steps=150,\n",
    "    accelerator=\"cuda\",\n",
    "    devices=1,\n",
    "    max_epochs=params[\"max_epochs\"],\n",
    "    val_check_interval=1.0,\n",
    "    enable_progress_bar=True,\n",
    "    num_sanity_val_steps=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Yedroudj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log model summary\n",
    "neptune_logger.log_model_summary(model=model, max_depth=-1)\n",
    "\n",
    "# Log hyperparameters\n",
    "neptune_logger.log_hyperparams(params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "best_model_path = model_checkpoint.best_model_path\n",
    "print(best_model_path)\n",
    "best_model = Yedroudj.load_from_checkpoint(best_model_path)\n",
    "trainer.test(best_model, datamodule=data_module)\n",
    "\n",
    "neptune_logger.experiment.stop()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stego",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
